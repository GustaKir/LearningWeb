Title: Connecting to Data in Streamlit
URL: https://docs.streamlit.io/develop/concepts/connections/connecting-to-data
Summary: This section explains how to connect to existing data sources in Streamlit easily and securely. It highlights the use of a secrets or credentials file to manage multiple connection configurations for different environments, using the `st.connection` function for runtime flexibility.
---

pp to your existing data sources is effectively a one-liner. It also reduces the risk of accidentally checking in your credentials to git since they don't need to exist in the project repository.
For cases where you have multiple similar data sources that you connect to during local development (such as a local vs. staging database), you can define different connection sections in your secrets or credentials file for different environments and then decide which to use at runtime. `st.connection` supports this with the _`name=env:<MY_NAME_VARIABLE>`_syntax.
E.g., say I have a local and a staging MySQL database and want to connect my app to either at different times. I could create a global secrets file like this:
`# ~/.streamlit/secrets.toml [connections.local] url = "mysql://me:****@localhost:3306/local_db" [connections.staging] url = "mysql://jdoe:******@staging.acmecorp.com:3306/staging_db" `
Then I can configure my app connection to take its name from a specified environment variable
`# streamlit_app.py import streamlit as st conn = st.connection("env:DB_CONN", "sql") df = conn.query("select * from mytable") # ... `
Now I can specify whether to connect to local or staging at runtime by setting the `DB_CONN` environment variable.
`# connect to local DB_CONN=local streamlit run streamlit_app.py # connect to staging DB_CONN=staging streamlit run streamlit_app.py `
### [](https://docs.streamlit.io/develop/concepts/connections/connecting-to-data#advanced-sqlconnection-configuration)Advanced SQLConnection configuration
The [SQLConnection](https://docs.streamlit.io/develop/api-reference/connections/st.connections.sqlconnection) configuration uses SQLAlchemy `create_engine()` function. It will take a single URL argument or attempt to construct a URL from several parts (username, database, host, and so on) using [`SQLAlchemy.engine.URL.create()`](https://docs.sqlalchemy.org/en/20/core/engines.html#sqlalchemy.engine.URL.create).
Several popular SQLAlchemy dialects, such as Snowflake and Google BigQuery, can be configured using additional arguments to `create_engine()` besides the URL. These can be passed as `**kwargs` to the [st.connection](https://docs.streamlit.io/develop/api-reference/connections/st.connection) call directly or specified in an additional secrets section called `create_engine_kwargs`.
E.g. snowflake-sqlalchemy takes an additional [`connect_args`](https://docs.sqlalchemy.org/en/20/core/engines.html#sqlalchemy.create_engine.params.connect_args) argument as a dictionary for configuration that isnâ€™t supported in the URL. These could be specified as follows:
`# .streamlit/secrets.toml [connections.snowflake] url = "snowflake://<user_login_name>@<account_identifier>/" [connections.snowflake.create_engine_kwargs.connect_args] authenticator = "externalbrowser" warehouse = "xxx" role = "xxx" `
`# streamlit_app.py import streamlit as st # url and connect_args from secrets.toml above are picked up and used here conn = st.connection("snowflake", "sql") # ... `
Alternatively, this could be specified entirely in `**kwargs`.
`# streamlit_app.py import streamlit as st # secrets.toml is not needed conn = st.connection( "snowflake", "sql",   url = "snowflake://<user_login_name>@<account_identifier>/",   connect_args = dict(     authenticator = "externalbrowser",     warehouse = "xxx",     role = "xxx", ) ) # ... `
You can also provide both kwargs and secrets.toml values, and they will be merged (typically, kwargs take precedence).
### [](https://docs.streamlit.io/develop/concepts/connections/connecting-to-data#connection-considerations-in-frequently-used-or-long-running-apps)Connection considerations in frequently used or long-running apps
By default, connection objects are cached without expiration using [`st.cache_resource`](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.cache_resource). In most cases this is desired. You can do `st.connection('myconn', type=MyConnection, ttl=<N>)` if you want the connection object to expire after some time.
Many connection types are expected to be long-running or completely stateless, so expiration is unnecessary. Suppose a connection becomes stale (such as a cached token expiring or a server-side connection being closed). In that case, every connection has a `reset()` method, which will invalidate the cached version and cause Streamlit to recreate the connection the next time it is retrieved
Convenience methods like `query()` and `read()` will typically cache results by default using [`st.cache_data`](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.cache_data) without an expiration. When an app can run many different read operations with large results, it can cause high memory usage over time and results to become stale in a long-running app, the same as with any other usage of `st.cache_data`. For production use cases, we recommend setting an appropriate `ttl` on these read operations, such as `conn.read('path/to/file', ttl="1d")`.