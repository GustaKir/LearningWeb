Title: Enhancing a Streamlit App for ChatGPT Functionality
URL: https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps
Summary: This section details updates to make a Streamlit app resemble ChatGPT more closely by initializing an OpenAI API client, setting a default model, and managing chat history. It includes code for displaying previous messages and accepting user input to maintain a conversational flow.
---

We'll also add a few more tweaks to make the app more ChatGPT-like.
`import streamlit as st from openai import OpenAI st.title("ChatGPT-like clone") # Set OpenAI API key from Streamlit secrets client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"]) # Set a default model if "openai_model" not in st.session_state:   st.session_state["openai_model"] = "gpt-3.5-turbo" # Initialize chat history if "messages" not in st.session_state:   st.session_state.messages = [] # Display chat messages from history on app rerun for message in st.session_state.messages: with st.chat_message(message["role"]):     st.markdown(message["content"]) # Accept user input if prompt := st.chat_input("What is up?"): # Add user message to chat history   st.session_state.messages.append({"role": "user", "content": prompt}) # Display user message in chat message container with st.chat_message("user"):     st.markdown(prompt) `
All that's changed is that we've added a default model to `st.session_state` and set our OpenAI API key from Streamlit secrets. Here's where it gets interesting. We can replace our emulated stream with the model's responses from OpenAI:
` # Display assistant response in chat message container with st.chat_message("assistant"):     stream = client.chat.completions.create(       model=st.session_state["openai_model"],       messages=[ {"role": m["role"], "content": m["content"]} for m in st.session_state.messages       ],       stream=True, )     response = st.write_stream(stream)   st.session_state.messages.append({"role": "assistant", "content": response}) `
Above, we've replaced the list of responses with a call to [`OpenAI().chat.completions.create`](https://platform.openai.com/docs/guides/text-generation/chat-completions-api). We've set `stream=True` to stream the responses to the frontend. In the API call, we pass the model name we hardcoded in session state and pass the chat history as a list of messages. We also pass the `role` and `content` of each message in the chat history. Finally, OpenAI returns a stream of responses (split into chunks of tokens), which we iterate through and display each chunk.
Putting it all together, here's the full code for our ChatGPT-like app and the result:
View full code _expand_more_
`from openai import OpenAI import streamlit as st st.title("ChatGPT-like clone") client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"]) if "openai_model" not in st.session_state:   st.session_state["openai_model"] = "gpt-3.5-turbo" if "messages" not in st.session_state:   st.session_state.messages = [] for message in st.session_state.messages: with st.chat_message(message["role"]):     st.markdown(message["content"]) if prompt := st.chat_input("What is up?"):   st.session_state.messages.append({"role": "user", "content": prompt}) with st.chat_message("user"):     st.markdown(prompt) with st.chat_message("assistant"):     stream = client.chat.completions.create(       model=st.session_state["openai_model"],       messages=[ {"role": m["role"], "content": m["content"]} for m in st.session_state.messages       ],       stream=True, )     response = st.write_stream(stream)   st.session_state.messages.append({"role": "assistant", "content": response}) `
![](https://docs.streamlit.io/images/knowledge-base/chatgpt-clone.gif)
[Built with Streamlit ðŸŽˆ](https://streamlit.io)
[Fullscreen _open_in_new_](https://doc-chat-llm.streamlit.app/?utm_medium=oembed)
Congratulations! You've built your own ChatGPT-like app in less than 50 lines of code.
We're very excited to see what you'll build with Streamlit's chat elements. Experiment with different models and tweak the code to build your own conversational apps. If you build something cool, let us know on the [Forum](https://discuss.streamlit.io/c/streamlit-examples/9) or check out some other [Generative AI apps](https://streamlit.io/generative-ai) for inspiration. ðŸŽˆ
[Previous: Chat & LLM apps](https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps)[Next: Build an LLM app using LangChain](https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/llm-quickstart) _forum_
### Still have questions?
Our [forums](https://discuss.streamlit.io) are full of helpful information and Streamlit experts.
[Home](https://docs.streamlit.io/)Contact Us[Community](https://discuss.streamlit.io)[](https://github.com/streamlit "GitHub")[](https://www.youtube.com/channel/UC3LD42rjj-Owtxsa6PwGU5Q "YouTube")[](https://twitter.com/streamlit "Twitter")[](https://www.linkedin.com/company/streamlit "LinkedIn")[](https://info.snowflake.com/streamlit-newsletter-sign-up.html "Newsletter")
Â© 2025 Snowflake Inc.Cookie policy
 _forum_ Ask AI