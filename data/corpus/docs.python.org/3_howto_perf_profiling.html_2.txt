Title: Profiling Python Performance with Perf
URL: https://docs.python.org/3/howto/perf_profiling.html
Summary: This document section outlines how to use Python's `sys` module to enable performance profiling with `perf`. It provides an example code snippet for activating and deactivating the profiling stack, as well as command-line instructions for recording and reporting profiling data. Additionally, it advises compiling Python with specific flags to optimize the profiling results, noting the importance of having the appropriate compile options to ensure accurate stack unwinding.
---

```

Example, using the [`sys`](https://docs.python.org/3/library/sys.html#module-sys "sys: Access system-specific parameters and functions.") APIs in file `example.py`:
```
importsys
sys.activate_stack_trampoline("perf")
do_profiled_stuff()
sys.deactivate_stack_trampoline()
non_profiled_stuff()

```

…then:
```
$ perfrecord-F9999-g-operf.datapython./example.py
$ perfreport-g-iperf.data

```

## How to obtain the best results[¶](https://docs.python.org/3/howto/perf_profiling.html#how-to-obtain-the-best-results "Link to this heading")
For best results, Python should be compiled with `CFLAGS="-fno-omit-frame-pointer -mno-omit-leaf-frame-pointer"` as this allows profilers to unwind using only the frame pointer and not on DWARF debug information. This is because as the code that is interposed to allow `perf` support is dynamically generated it doesn’t have any DWARF debugging information available.
You can check if your system has been compiled with this flag by running:
```
$ python-msysconfig|grep'no-omit-frame-pointer'

```

If you don’t see any output it means that your interpreter has not been compiled with frame pointers and therefore it may not be able to show Python functions in the output of `perf`.
## How to work without frame pointers[¶](https://docs.python.org/3/howto/perf_profiling.html#how-to-work-without-frame-pointers "Link to this heading")
If you are working with a Python interpreter that has been compiled without frame pointers, you can still use the `perf` profiler, but the overhead will be a bit higher because Python needs to generate unwinding information for every Python function call on the fly. Additionally, `perf` will take more time to process the data because it will need to use the DWARF debugging information to unwind the stack and this is a slow process.
To enable this mode, you can use the environment variable [`PYTHON_PERF_JIT_SUPPORT`](https://docs.python.org/3/using/cmdline.html#envvar-PYTHON_PERF_JIT_SUPPORT) or the [`-X perf_jit`](https://docs.python.org/3/using/cmdline.html#cmdoption-X) option, which will enable the JIT mode for the `perf` profiler.
Note
Due to a bug in the `perf` tool, only `perf` versions higher than v6.8 will work with the JIT mode. The fix was also backported to the v6.7.2 version of the tool.
Note that when checking the version of the `perf` tool (which can be done by running `perf version`) you must take into account that some distros add some custom version numbers including a `-` character. This means that `perf 6.7-3` is not necessarily `perf 6.7.3`.
When using the perf JIT mode, you need an extra step before you can run `perf report`. You need to call the `perf inject` command to inject the JIT information into the `perf.data` file.:
```
$ perfrecord-F9999-g-k1--call-graphdwarf-operf.datapython-Xperf_jitmy_script.py
$ perfinject-iperf.data--jit--outputperf.jit.data
$ perfreport-g-iperf.jit.data

```

or using the environment variable:
```
$ PYTHON_PERF_JIT_SUPPORT=1perfrecord-F9999-g--call-graphdwarf-operf.datapythonmy_script.py
$ perfinject-iperf.data--jit--outputperf.jit.data
$ perfreport-g-iperf.jit.data

```

`perf inject --jit` command will read `perf.data`, automatically pick up the perf dump file that Python creates (in `/tmp/perf-$PID.dump`), and then create `perf.jit.data` which merges all the JIT information together. It should also create a lot of `jitted-XXXX-N.so` files in the current directory which are ELF images for all the JIT trampolines that were created by Python.
Warning
When using `--call-graph dwarf`, the `perf` tool will take snapshots of the stack of the process being profiled and save the information in the `perf.data` file. By default, the size of the stack dump is 8192 bytes, but you can change the size by passing it after a comma like `--call-graph dwarf,16384`.
The size of the stack dump is important because if the size is too small `perf` will not be able to unwind the stack and the output will be incomplete. On the other hand, if the size is too big, then `perf` won’t be able to sample the process as frequently as it would like as the overhead will be higher.
The stack size is particularly important when profiling Python code compiled with low optimization levels (like `-O0`), as these builds tend to have larger stack frames. If you are compiling Python with `-O0` and not seeing Python functions in your profiling output, try increasing the stack dump size to 65528 bytes (the maximum):
```
$ perfrecord-F9999-g-k1--call-graphdwarf,65528-operf.datapython-Xperf_jitmy_script.py