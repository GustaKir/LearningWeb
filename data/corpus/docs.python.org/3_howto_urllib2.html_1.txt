Title: Introduction to urllib.request Module
URL: https://docs.python.org/3/howto/urllib2.html
Summary: The urllib.request module in Python simplifies URL fetching through the _urlopen_ function, supporting various protocols like HTTP and FTP. It provides basic functionalities as well as advanced features for handling authentication, cookies, and proxies via handlers and openers. The tutorial emphasizes the usage of HTTP, while also noting the need for an understanding of the HyperText Transfer Protocol for error handling and complex scenarios.
---

**urllib.request** is a Python module for fetching URLs (Uniform Resource Locators). It offers a very simple interface, in the form of the _urlopen_ function. This is capable of fetching URLs using a variety of different protocols. It also offers a slightly more complex interface for handling common situations - like basic authentication, cookies, proxies and so on. These are provided by objects called handlers and openers.
urllib.request supports fetching URLs for many “URL schemes” (identified by the string before the `":"` in URL - for example `"ftp"` is the URL scheme of `"ftp://python.org/"`) using their associated network protocols (e.g. FTP, HTTP). This tutorial focuses on the most common case, HTTP.
For straightforward situations _urlopen_ is very easy to use. But as soon as you encounter errors or non-trivial cases when opening HTTP URLs, you will need some understanding of the HyperText Transfer Protocol. The most comprehensive and authoritative reference to HTTP is [**RFC 2616**](https://datatracker.ietf.org/doc/html/rfc2616.html). This is a technical document and not intended to be easy to read. This HOWTO aims to illustrate using _urllib_ , with enough detail about HTTP to help you through. It is not intended to replace the [`urllib.request`](https://docs.python.org/3/library/urllib.request.html#module-urllib.request "urllib.request: Extensible library for opening URLs.") docs, but is supplementary to them.
## Fetching URLs[¶](https://docs.python.org/3/howto/urllib2.html#fetching-urls "Link to this heading")
The simplest way to use urllib.request is as follows:
```
importurllib.request
with urllib.request.urlopen('http://python.org/') as response:
  html = response.read()

```

If you wish to retrieve a resource via URL and store it in a temporary location, you can do so via the [`shutil.copyfileobj()`](https://docs.python.org/3/library/shutil.html#shutil.copyfileobj "shutil.copyfileobj") and [`tempfile.NamedTemporaryFile()`](https://docs.python.org/3/library/tempfile.html#tempfile.NamedTemporaryFile "tempfile.NamedTemporaryFile") functions:
```
importshutil
importtempfile
importurllib.request
with urllib.request.urlopen('http://python.org/') as response:
  with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
    shutil.copyfileobj(response, tmp_file)
with open(tmp_file.name) as html:
  pass

```

Many uses of urllib will be that simple (note that instead of an ‘http:’ URL we could have used a URL starting with ‘ftp:’, ‘file:’, etc.). However, it’s the purpose of this tutorial to explain the more complicated cases, concentrating on HTTP.
HTTP is based on requests and responses - the client makes requests and servers send responses. urllib.request mirrors this with a `Request` object which represents the HTTP request you are making. In its simplest form you create a Request object that specifies the URL you want to fetch. Calling `urlopen` with this Request object returns a response object for the URL requested. This response is a file-like object, which means you can for example call `.read()` on the response:
```
importurllib.request
req = urllib.request.Request('http://python.org/')
with urllib.request.urlopen(req) as response:
  the_page = response.read()

```

Note that urllib.request makes use of the same Request interface to handle all URL schemes. For example, you can make an FTP request like so:
```
req = urllib.request.Request('ftp://example.com/')

```

In the case of HTTP, there are two extra things that Request objects allow you to do: First, you can pass data to be sent to the server. Second, you can pass extra information (“metadata”) _about_ the data or about the request itself, to the server - this information is sent as HTTP “headers”. Let’s look at each of these in turn.
### Data[¶](https://docs.python.org/3/howto/urllib2.html#data "Link to this heading")
Sometimes you want to send data to a URL (often the URL will refer to a CGI (Common Gateway Interface) script or other web application). With HTTP, this is often done using what’s known as a **POST** request. This is often what your browser does when you submit a HTML form that you filled in on the web. Not all POSTs have to come from forms: you can use a POST to transmit arbitrary data to your own application. In the common case of HTML forms, the data needs to be encoded in a standard way, and then passed to the Request object as the `data` argument. The encoding is done using a function from the [`urllib.parse`](https://docs.python.org/3/library/urllib.parse.html#module-urllib.parse "urllib.parse: Parse URLs into or assemble them from components.") library.