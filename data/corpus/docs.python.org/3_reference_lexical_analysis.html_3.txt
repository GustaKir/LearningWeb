Title: Lexical Analysis in Python
URL: https://docs.python.org/3/reference/lexical_analysis.html
Summary: This section discusses how whitespace is used between tokens in Python, emphasizing that it can be interchangeable except at the beginning of a line or within string literals. It also introduces other token categories, including identifiers, keywords, literals, operators, and delimiters.
---

```

(Actually, the first three errors are detected by the parser; only the last error is found by the lexical analyzer — the indentation of `return r` does not match a level popped off the stack.)
### 2.1.9. Whitespace between tokens[¶](https://docs.python.org/3/reference/lexical_analysis.html#whitespace-between-tokens "Link to this heading")
Except at the beginning of a logical line or in string literals, the whitespace characters space, tab and formfeed can be used interchangeably to separate tokens. Whitespace is needed between two tokens only if their concatenation could otherwise be interpreted as a different token (e.g., ab is one token, but a b is two tokens).
## 2.2. Other tokens[¶](https://docs.python.org/3/reference/lexical_analysis.html#other-tokens "Link to this heading")
Besides NEWLINE, INDENT and DEDENT, the following categories of tokens exist: _identifiers_ , _keywords_ , _literals_ , _operators_ , and _delimiters_. Whitespace characters (other than line terminators, discussed earlier) are not tokens, but serve to delimit tokens. Where ambiguity exists, a token comprises the longest possible string that forms a legal token, when read from left to right.
## 2.3. Identifiers and keywords[¶](https://docs.python.org/3/reference/lexical_analysis.html#identifiers "Link to this heading")
Identifiers (also referred to as _names_) are described by the following lexical definitions.
The syntax of identifiers in Python is based on the Unicode standard annex UAX-31, with elaboration and changes as defined below; see also [**PEP 3131**](https://peps.python.org/pep-3131/) for further details.
Within the ASCII range (U+0001..U+007F), the valid characters for identifiers include the uppercase and lowercase letters `A` through `Z`, the underscore `_` and, except for the first character, the digits `0` through `9`. Python 3.0 introduced additional characters from outside the ASCII range (see [**PEP 3131**](https://peps.python.org/pep-3131/)). For these characters, the classification uses the version of the Unicode Character Database as included in the [`unicodedata`](https://docs.python.org/3/library/unicodedata.html#module-unicodedata "unicodedata: Access the Unicode Database.") module.
Identifiers are unlimited in length. Case is significant.
```
**identifier**  ::= [xid_start](https://docs.python.org/3/reference/lexical_analysis.html#grammar-token-python-grammar-xid_start) [xid_continue](https://docs.python.org/3/reference/lexical_analysis.html#grammar-token-python-grammar-xid_continue)*
**id_start**   ::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property>
**id_continue** ::= <all characters in [id_start](https://docs.python.org/3/reference/lexical_analysis.html#grammar-token-python-grammar-id_start), plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property>
**xid_start**  ::= <all characters in [id_start](https://docs.python.org/3/reference/lexical_analysis.html#grammar-token-python-grammar-id_start) whose NFKC normalization is in "id_start xid_continue*">
**xid_continue** ::= <all characters in [id_continue](https://docs.python.org/3/reference/lexical_analysis.html#grammar-token-python-grammar-id_continue) whose NFKC normalization is in "id_continue*">

```

The Unicode category codes mentioned above stand for:
  * _Lu_ - uppercase letters
  * _Ll_ - lowercase letters
  * _Lt_ - titlecase letters
  * _Lm_ - modifier letters
  * _Lo_ - other letters
  * _Nl_ - letter numbers
  * _Mn_ - nonspacing marks
  * _Mc_ - spacing combining marks
  * _Nd_ - decimal numbers
  * _Pc_ - connector punctuations
  * _Other_ID_Start_ - explicit list of characters in [PropList.txt](https://www.unicode.org/Public/15.1.0/ucd/PropList.txt) to support backwards compatibility
  * _Other_ID_Continue_ - likewise


All identifiers are converted into the normal form NFKC while parsing; comparison of identifiers is based on NFKC.
A non-normative HTML file listing all valid identifier characters for Unicode 15.1.0 can be found at <https://www.unicode.org/Public/15.1.0/ucd/DerivedCoreProperties.txt>
### 2.3.1. Keywords[¶](https://docs.python.org/3/reference/lexical_analysis.html#keywords "Link to this heading")
The following identifiers are used as reserved words, or _keywords_ of the language, and cannot be used as ordinary identifiers. They must be spelled exactly as written here:
```
False   await   else    import   pass
None    break   except   in     raise
True    class   finally  is     return
and    continue  for    lambda   try
as     def    from    nonlocal  while
assert   del    global   not    with
async   elif    if     or     yield