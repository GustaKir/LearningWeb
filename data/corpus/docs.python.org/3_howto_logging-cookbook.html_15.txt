Title: Logging to a Single File from Multiple Processes
URL: https://docs.python.org/3/howto/logging-cookbook.html
Summary: This section discusses the challenges of logging to a single file from multiple processes in Python, noting that while logging is thread-safe, it is not supported across processes. It suggests using a `SocketHandler` for logging, where all processes send logs to a socket server that writes them to a file.
---

```

## Logging to a single file from multiple processes[¶](https://docs.python.org/3/howto/logging-cookbook.html#logging-to-a-single-file-from-multiple-processes "Link to this heading")
Although logging is thread-safe, and logging to a single file from multiple threads in a single process _is_ supported, logging to a single file from _multiple processes_ is _not_ supported, because there is no standard way to serialize access to a single file across multiple processes in Python. If you need to log to a single file from multiple processes, one way of doing this is to have all the processes log to a [`SocketHandler`](https://docs.python.org/3/library/logging.handlers.html#logging.handlers.SocketHandler "logging.handlers.SocketHandler"), and have a separate process which implements a socket server which reads from the socket and logs to file. (If you prefer, you can dedicate one thread in one of the existing processes to perform this function.) [This section](https://docs.python.org/3/howto/logging-cookbook.html#network-logging) documents this approach in more detail and includes a working socket receiver which can be used as a starting point for you to adapt in your own applications.
You could also write your own handler which uses the [`Lock`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Lock "multiprocessing.Lock") class from the [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "multiprocessing: Process-based parallelism.") module to serialize access to the file from your processes. The stdlib [`FileHandler`](https://docs.python.org/3/library/logging.handlers.html#logging.FileHandler "logging.FileHandler") and subclasses do not make use of [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "multiprocessing: Process-based parallelism.").
Alternatively, you can use a `Queue` and a [`QueueHandler`](https://docs.python.org/3/library/logging.handlers.html#logging.handlers.QueueHandler "logging.handlers.QueueHandler") to send all logging events to one of the processes in your multi-process application. The following example script demonstrates how you can do this; in the example a separate listener process listens for events sent by other processes and logs them according to its own logging configuration. Although the example only demonstrates one way of doing it (for example, you may want to use a listener thread rather than a separate listener process – the implementation would be analogous) it does allow for completely different logging configurations for the listener and the other processes in your application, and can be used as the basis for code meeting your own specific requirements: