Title: Token Types in Python's Token Library
URL: https://docs.python.org/3/library/token.html
Summary: This section describes various token types in Python's token library, specifically focusing on `TYPE_IGNORE`, which indicates a `type: ignore` comment, and `TYPE_COMMENT`, which indicates a recognized type comment. Both token types are produced under the `PyCF_TYPE_COMMENTS` flag instead of regular comment tokens.
---

token.TYPE_IGNORE[¶](https://docs.python.org/3/library/token.html#token.TYPE_IGNORE "Link to this definition")
    
Token value indicating that a `type: ignore` comment was recognized. Such tokens are produced instead of regular [`COMMENT`](https://docs.python.org/3/library/token.html#token.COMMENT "token.COMMENT") tokens only with the [`PyCF_TYPE_COMMENTS`](https://docs.python.org/3/library/ast.html#ast.PyCF_TYPE_COMMENTS "ast.PyCF_TYPE_COMMENTS") flag. 

token.TYPE_COMMENT[¶](https://docs.python.org/3/library/token.html#token.TYPE_COMMENT "Link to this definition")
    
Token value indicating that a type comment was recognized. Such tokens are produced instead of regular [`COMMENT`](https://docs.python.org/3/library/token.html#token.COMMENT "token.COMMENT") tokens only with the [`PyCF_TYPE_COMMENTS`](https://docs.python.org/3/library/ast.html#ast.PyCF_TYPE_COMMENTS "ast.PyCF_TYPE_COMMENTS") flag. 

token.SOFT_KEYWORD[¶](https://docs.python.org/3/library/token.html#token.SOFT_KEYWORD "Link to this definition")
    
Token value indicating a [soft keyword](https://docs.python.org/3/reference/lexical_analysis.html#soft-keywords).
The tokenizer never produces this value. To check for a soft keyword, pass a [`NAME`](https://docs.python.org/3/library/token.html#token.NAME "token.NAME") token’s string to [`keyword.issoftkeyword()`](https://docs.python.org/3/library/keyword.html#keyword.issoftkeyword "keyword.issoftkeyword"). 

token.ERRORTOKEN[¶](https://docs.python.org/3/library/token.html#token.ERRORTOKEN "Link to this definition")
    
Token value used to indicate wrong input.
The [`tokenize`](https://docs.python.org/3/library/tokenize.html#module-tokenize "tokenize: Lexical scanner for Python source code.") module generally indicates errors by raising exceptions instead of emitting this token. It can also emit tokens such as [`OP`](https://docs.python.org/3/library/token.html#token.OP "token.OP") or [`NAME`](https://docs.python.org/3/library/token.html#token.NAME "token.NAME") with strings that are later rejected by the parser.
The remaining tokens represent specific [operators](https://docs.python.org/3/reference/lexical_analysis.html#operators) and [delimiters](https://docs.python.org/3/reference/lexical_analysis.html#delimiters). (The [`tokenize`](https://docs.python.org/3/library/tokenize.html#module-tokenize "tokenize: Lexical scanner for Python source code.") module reports these as [`OP`](https://docs.python.org/3/library/token.html#token.OP "token.OP"); see `exact_type` in the [`tokenize`](https://docs.python.org/3/library/tokenize.html#module-tokenize "tokenize: Lexical scanner for Python source code.") documentation for details.)
Token | Value  
---|--- 

token.LPAR[¶](https://docs.python.org/3/library/token.html#token.LPAR "Link to this definition")
| `"("` 

token.RPAR[¶](https://docs.python.org/3/library/token.html#token.RPAR "Link to this definition")
| `")"` 

token.LSQB[¶](https://docs.python.org/3/library/token.html#token.LSQB "Link to this definition")
| `"["` 

token.RSQB[¶](https://docs.python.org/3/library/token.html#token.RSQB "Link to this definition")
| `"]"` 

token.COLON[¶](https://docs.python.org/3/library/token.html#token.COLON "Link to this definition")
| `":"` 

token.COMMA[¶](https://docs.python.org/3/library/token.html#token.COMMA "Link to this definition")
| `","` 

token.SEMI[¶](https://docs.python.org/3/library/token.html#token.SEMI "Link to this definition")
| `";"` 

token.PLUS[¶](https://docs.python.org/3/library/token.html#token.PLUS "Link to this definition")
| `"+"` 

token.MINUS[¶](https://docs.python.org/3/library/token.html#token.MINUS "Link to this definition")
| `"-"` 

token.STAR[¶](https://docs.python.org/3/library/token.html#token.STAR "Link to this definition")
| `"*"` 

token.SLASH[¶](https://docs.python.org/3/library/token.html#token.SLASH "Link to this definition")
| `"/"` 

token.VBAR[¶](https://docs.python.org/3/library/token.html#token.VBAR "Link to this definition")
| `"|"` 

token.AMPER[¶](https://docs.python.org/3/library/token.html#token.AMPER "Link to this definition")
| `"&"` 

token.LESS[¶](https://docs.python.org/3/library/token.html#token.LESS "Link to this definition")
| `"<"` 

token.GREATER[¶](https://docs.python.org/3/library/token.html#token.GREATER "Link to this definition")
| `">"` 

token.EQUAL[¶](https://docs.python.org/3/library/token.html#token.EQUAL "Link to this definition")
| `"="` 

token.DOT[¶](https://docs.python.org/3/library/token.html#token.DOT "Link to this definition")
| `"."` 

token.PERCENT[¶](https://docs.python.org/3/library/token.html#token.PERCENT "Link to this definition")
| `"%"` 

token.LBRACE[¶](https://docs.python.org/3/library/token.html#token.LBRACE "Link to this definition")
| `"{"` 

token.RBRACE[¶](https://docs.python.org/3/library/token.html#token.RBRACE "Link to this definition")
| `"}"` 

token.EQEQUAL[¶](https://docs.python.org/3/library/token.html#token.EQEQUAL "Link to this definition")
| `"=="`