Title: ProcessPoolExecutor Class in concurrent.futures
URL: https://docs.python.org/3/library/concurrent.futures.html
Summary: The ProcessPoolExecutor class is a subclass of Executor that enables asynchronous execution of calls with a pool of up to max_workers processes. The max_workers parameter defaults to the number of CPU cores if not specified. A ValueError is raised for invalid values, with Windows having a maximum limit of 61.
---

_class_ concurrent.futures.ProcessPoolExecutor(_max_workers =None_, _mp_context =None_, _initializer =None_, _initargs =()_, _max_tasks_per_child =None_)[¶](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor "Link to this definition")
    
An [`Executor`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor "concurrent.futures.Executor") subclass that executes calls asynchronously using a pool of at most _max_workers_ processes. If _max_workers_ is `None` or not given, it will default to [`os.process_cpu_count()`](https://docs.python.org/3/library/os.html#os.process_cpu_count "os.process_cpu_count"). If _max_workers_ is less than or equal to `0`, then a [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError "ValueError") will be raised. On Windows, _max_workers_ must be less than or equal to `61`. If it is not then [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError "ValueError") will be raised. If _max_workers_ is `None`, then the default chosen will be at most `61`, even if more processors are available. _mp_context_ can be a [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "multiprocessing: Process-based parallelism.") context or `None`. It will be used to launch the workers. If _mp_context_ is `None` or not given, the default [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "multiprocessing: Process-based parallelism.") context is used. See [Contexts and start methods](https://docs.python.org/3/library/multiprocessing.html#multiprocessing-start-methods).
_initializer_ is an optional callable that is called at the start of each worker process; _initargs_ is a tuple of arguments passed to the initializer. Should _initializer_ raise an exception, all currently pending jobs will raise a [`BrokenProcessPool`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.process.BrokenProcessPool "concurrent.futures.process.BrokenProcessPool"), as well as any attempt to submit more jobs to the pool.
_max_tasks_per_child_ is an optional argument that specifies the maximum number of tasks a single process can execute before it will exit and be replaced with a fresh worker process. By default _max_tasks_per_child_ is `None` which means worker processes will live as long as the pool. When a max is specified, the “spawn” multiprocessing start method will be used by default in absence of a _mp_context_ parameter. This feature is incompatible with the “fork” start method.
Changed in version 3.3: When one of the worker processes terminates abruptly, a [`BrokenProcessPool`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.process.BrokenProcessPool "concurrent.futures.process.BrokenProcessPool") error is now raised. Previously, behaviour was undefined but operations on the executor or its futures would often freeze or deadlock.
Changed in version 3.7: The _mp_context_ argument was added to allow users to control the start_method for worker processes created by the pool.
Added the _initializer_ and _initargs_ arguments.
Note
The default [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "multiprocessing: Process-based parallelism.") start method (see [Contexts and start methods](https://docs.python.org/3/library/multiprocessing.html#multiprocessing-start-methods)) will change away from _fork_ in Python 3.14. Code that requires _fork_ be used for their [`ProcessPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor "concurrent.futures.ProcessPoolExecutor") should explicitly specify that by passing a `mp_context=multiprocessing.get_context("fork")` parameter.
Changed in version 3.11: The _max_tasks_per_child_ argument was added to allow users to control the lifetime of workers in the pool.
Changed in version 3.12: On POSIX systems, if your application has multiple threads and the [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing "multiprocessing: Process-based parallelism.") context uses the `"fork"` start method: The [`os.fork()`](https://docs.python.org/3/library/os.html#os.fork "os.fork") function called internally to spawn workers may raise a [`DeprecationWarning`](https://docs.python.org/3/library/exceptions.html#DeprecationWarning "DeprecationWarning"). Pass a _mp_context_ configured to use a different start method. See the [`os.fork()`](https://docs.python.org/3/library/os.html#os.fork "os.fork") documentation for further explanation.
Changed in version 3.13: _max_workers_ uses [`os.process_cpu_count()`](https://docs.python.org/3/library/os.html#os.process_cpu_count "os.process_cpu_count") by default, instead of [`os.cpu_count()`](https://docs.python.org/3/library/os.html#os.cpu_count "os.cpu_count").
##