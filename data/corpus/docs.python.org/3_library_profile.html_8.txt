Title: get_stats_profile Method and Deterministic Profiling
URL: https://docs.python.org/3/library/profile.html
Summary: The get_stats_profile() method returns a StatsProfile instance containing a mapping of function names to their corresponding FunctionProfile instances, which include data on execution time and call counts. The document also introduces deterministic profiling, highlighting its method of tracking all function events and precise timings, contrasting with statistical profiling.
---

get_stats_profile()[¶](https://docs.python.org/3/library/profile.html#pstats.Stats.get_stats_profile "Link to this definition")
    
This method returns an instance of StatsProfile, which contains a mapping of function names to instances of FunctionProfile. Each FunctionProfile instance holds information related to the function’s profile such as how long the function took to run, how many times it was called, etc…
Added in version 3.9: Added the following dataclasses: StatsProfile, FunctionProfile. Added the following function: get_stats_profile.
## What Is Deterministic Profiling?[¶](https://docs.python.org/3/library/profile.html#what-is-deterministic-profiling "Link to this heading")
_Deterministic profiling_ is meant to reflect the fact that all _function call_ , _function return_ , and _exception_ events are monitored, and precise timings are made for the intervals between these events (during which time the user’s code is executing). In contrast, _statistical profiling_ (which is not done by this module) randomly samples the effective instruction pointer, and deduces where time is being spent. The latter technique traditionally involves less overhead (as the code does not need to be instrumented), but provides only relative indications of where time is being spent.
In Python, since there is an interpreter active during execution, the presence of instrumented code is not required in order to do deterministic profiling. Python automatically provides a _hook_ (optional callback) for each event. In addition, the interpreted nature of Python tends to add so much overhead to execution, that deterministic profiling tends to only add small processing overhead in typical applications. The result is that deterministic profiling is not that expensive, yet provides extensive run time statistics about the execution of a Python program.
Call count statistics can be used to identify bugs in code (surprising counts), and to identify possible inline-expansion points (high call counts). Internal time statistics can be used to identify “hot loops” that should be carefully optimized. Cumulative time statistics should be used to identify high level errors in the selection of algorithms. Note that the unusual handling of cumulative times in this profiler allows statistics for recursive implementations of algorithms to be directly compared to iterative implementations.
## Limitations[¶](https://docs.python.org/3/library/profile.html#limitations "Link to this heading")
One limitation has to do with accuracy of timing information. There is a fundamental problem with deterministic profilers involving accuracy. The most obvious restriction is that the underlying “clock” is only ticking at a rate (typically) of about .001 seconds. Hence no measurements will be more accurate than the underlying clock. If enough measurements are taken, then the “error” will tend to average out. Unfortunately, removing this first error induces a second source of error.
The second problem is that it “takes a while” from when an event is dispatched until the profiler’s call to get the time actually _gets_ the state of the clock. Similarly, there is a certain lag when exiting the profiler event handler from the time that the clock’s value was obtained (and then squirreled away), until the user’s code is once again executing. As a result, functions that are called many times, or call many functions, will typically accumulate this error. The error that accumulates in this fashion is typically less than the accuracy of the clock (less than one clock tick), but it _can_ accumulate and become very significant.
The problem is more important with [`profile`](https://docs.python.org/3/library/profile.html#module-profile "profile: Python source profiler.") than with the lower-overhead [`cProfile`](https://docs.python.org/3/library/profile.html#module-cProfile "cProfile"). For this reason, [`profile`](https://docs.python.org/3/library/profile.html#module-profile "profile: Python source profiler.") provides a means of calibrating itself for a given platform so that this error can be probabilistically (on the average) removed. After the profiler is calibrated, it will be more accurate (in a least square sense), but it will sometimes produce negative numbers (when call counts are exceptionally low, and the gods of probability work against you :-). ) Do _not_ be alarmed by negative numbers in the profile. They should _only_ appear if you have calibrated your profiler, and the results are actually better than without calibration.
## Calibration[¶](https://docs.python.org/3/library/profile.html#calibration "Link to this heading")
The profiler of the [`profile`](https://docs.python.org/3/library/profile.html#module-profile "profile: Python source profiler.") module subtracts a constant from each event handling time to compensate for the overhead of calling the time function, and socking away the results. By default, the constant is 0. The following procedure can be u