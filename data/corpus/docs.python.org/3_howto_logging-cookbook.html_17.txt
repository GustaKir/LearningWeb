Title: Logging in Python: Multi-Process Example
URL: https://docs.python.org/3/howto/logging-cookbook.html
Summary: This document presents a Python example of how to implement multi-process logging using the `logging` module. It defines functions for handling log records in a separate thread and for generating log messages in worker processes. The example emphasizes configuring a logging system that can handle messages from multiple processes efficiently.
---

```
importlogging
importlogging.config
importlogging.handlers
frommultiprocessingimport Process, Queue
importrandom
importthreading
importtime
deflogger_thread(q):
  while True:
    record = q.get()
    if record is None:
      break
    logger = logging.getLogger(record.name)
    logger.handle(record)

defworker_process(q):
  qh = logging.handlers.QueueHandler(q)
  root = logging.getLogger()
  root.setLevel(logging.DEBUG)
  root.addHandler(qh)
  levels = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,
       logging.CRITICAL]
  loggers = ['foo', 'foo.bar', 'foo.bar.baz',
        'spam', 'spam.ham', 'spam.ham.eggs']
  for i in range(100):
    lvl = random.choice(levels)
    logger = logging.getLogger(random.choice(loggers))
    logger.log(lvl, 'Message no. %d', i)
if __name__ == '__main__':
  q = Queue()
  d = {
    'version': 1,
    'formatters': {
      'detailed': {
        'class': 'logging.Formatter',
        'format': '%(asctime)s%(name)-15s%(levelname)-8s%(processName)-10s%(message)s'
      }
    },
    'handlers': {
      'console': {
        'class': 'logging.StreamHandler',
        'level': 'INFO',
      },
      'file': {
        'class': 'logging.FileHandler',
        'filename': 'mplog.log',
        'mode': 'w',
        'formatter': 'detailed',
      },
      'foofile': {
        'class': 'logging.FileHandler',
        'filename': 'mplog-foo.log',
        'mode': 'w',
        'formatter': 'detailed',
      },
      'errors': {
        'class': 'logging.FileHandler',
        'filename': 'mplog-errors.log',
        'mode': 'w',
        'level': 'ERROR',
        'formatter': 'detailed',
      },
    },
    'loggers': {
      'foo': {
        'handlers': ['foofile']
      }
    },
    'root': {
      'level': 'DEBUG',
      'handlers': ['console', 'file', 'errors']
    },
  }
  workers = []
  for i in range(5):
    wp = Process(target=worker_process, name='worker %d' % (i + 1), args=(q,))
    workers.append(wp)
    wp.start()
  logging.config.dictConfig(d)
  lp = threading.Thread(target=logger_thread, args=(q,))
  lp.start()
  # At this point, the main process could do some useful work of its own
  # Once it's done that, it can wait for the workers to terminate...
  for wp in workers:
    wp.join()
  # And now tell the logging thread to finish up, too
  q.put(None)
  lp.join()

```

This variant shows how you can e.g. apply configuration for particular loggers - e.g. the `foo` logger has a special handler which stores all events in the `foo` subsystem in a file `mplog-foo.log`. This will be used by the logging machinery in the main process (even though the logging events are generated in the worker processes) to direct the messages to the appropriate destinations.
### Using concurrent.futures.ProcessPoolExecutor[Â¶](https://docs.python.org/3/howto/logging-cookbook.html#using-concurrent-futures-processpoolexecutor "Link to this heading")
If you want to use [`concurrent.futures.ProcessPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor "concurrent.futures.ProcessPoolExecutor") to start your worker processes, you need to create the queue slightly differently. Instead of
```
queue = multiprocessing.Queue(-1)

```

you should use
```
queue = multiprocessing.Manager().Queue(-1) # also works with the examples above

```

and you can then replace the worker creation from this:
```
workers = []
for i in range(10):
  worker = multiprocessing.Process(target=worker_process,
                   args=(queue, worker_configurer))
  workers.append(worker)
  worker.start()
for w in workers:
  w.join()

```

to this (remembering to first import [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures "concurrent.futures: Execute computations concurrently using threads or processes.")):
```
with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:
  for i in range(10):
    executor.submit(worker_process, queue, worker_configurer)