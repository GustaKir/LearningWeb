Title: Understanding Parallel Processing with FastAPI
URL: https://fastapi.tiangolo.com/async/
Summary: The section illustrates the concept of parallel processing using an analogy of ordering burgers at a fast-food restaurant with multiple cashiers/cooks who prepare orders simultaneously. This emphasizes how tasks can be handled concurrently to improve efficiency.
---

## Parallel Burgers[¶](https://fastapi.tiangolo.com/async/#parallel-burgers "Permanent link")
Now let's imagine these aren't "Concurrent Burgers", but "Parallel Burgers".
You go with your crush to get parallel fast food.
You stand in line while several (let's say 8) cashiers that at the same time are cooks take the orders from the people in front of you.
Everyone before you is waiting for their burgers to be ready before leaving the counter because each of the 8 cashiers goes and prepares the burger right away before getting the next order.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-01.png)
Then it's finally your turn, you place your order of 2 very fancy burgers for your crush and you.
You pay 💸.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-02.png)
The cashier goes to the kitchen.
You wait, standing in front of the counter 🕙, so that no one else takes your burgers before you do, as there are no numbers for turns.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-03.png)
As you and your crush are busy not letting anyone get in front of you and take your burgers whenever they arrive, you cannot pay attention to your crush. 😞
This is "synchronous" work, you are "synchronized" with the cashier/cook 👨‍🍳. You have to wait 🕙 and be there at the exact moment that the cashier/cook 👨‍🍳 finishes the burgers and gives them to you, or otherwise, someone else might take them.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-04.png)
Then your cashier/cook 👨‍🍳 finally comes back with your burgers, after a long time waiting 🕙 there in front of the counter.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-05.png)
You take your burgers and go to the table with your crush.
You just eat them, and you are done. ⏹
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-06.png)
There was not much talk or flirting as most of the time was spent waiting 🕙 in front of the counter. 😞
Info
Beautiful illustrations by [Ketrina Thompson](https://www.instagram.com/ketrinadrawsalot). 🎨
In this scenario of the parallel burgers, you are a computer / program 🤖 with two processors (you and your crush), both waiting 🕙 and dedicating their attention ⏯ to be "waiting on the counter" 🕙 for a long time.
The fast food store has 8 processors (cashiers/cooks). While the concurrent burgers store might have had only 2 (one cashier and one cook).
But still, the final experience is not the best. 😞
This would be the parallel equivalent story for burgers. 🍔
For a more "real life" example of this, imagine a bank.
Up to recently, most of the banks had multiple cashiers 👨‍💼👨‍💼👨‍💼👨‍💼 and a big line 🕙🕙🕙🕙🕙🕙🕙🕙.
All of the cashiers doing all the work with one client after the other 👨‍💼⏯.
And you have to wait 🕙 in the line for a long time or you lose your turn.
You probably wouldn't want to take your crush 😍 with you to run errands at the bank 🏦.
### Burger Conclusion[¶](https://fastapi.tiangolo.com/async/#burger-conclusion "Permanent link")
In this scenario of "fast food burgers with your crush", as there is a lot of waiting 🕙, it makes a lot more sense to have a concurrent system ⏸🔀⏯.
This is the case for most of the web applications.
Many, many users, but your server is waiting 🕙 for their not-so-good connection to send their requests.
And then waiting 🕙 again for the responses to come back.
This "waiting" 🕙 is measured in microseconds, but still, summing it all, it's a lot of waiting in the end.
That's why it makes a lot of sense to use asynchronous ⏸🔀⏯ code for web APIs.
This kind of asynchronicity is what made NodeJS popular (even though NodeJS is not parallel) and that's the strength of Go as a programming language.
And that's the same level of performance you get with **FastAPI**.
And as you can have parallelism and asynchronicity at the same time, you get higher performance than most of the tested NodeJS frameworks and on par with Go, which is a compiled language closer to C [(all thanks to Starlette)](https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1).
### Is concurrency better than parallelism?[¶](https://fastapi.tiangolo.com/async/#is-concurrency-better-than-parallelism "Permanent link")
Nope! That's not the moral of the story.
Concurrency is different than parallelism. And it is better on **specific** scenarios that involve a lot of waiting. Because of that, it generally is a lot better than parallelism for web application development.