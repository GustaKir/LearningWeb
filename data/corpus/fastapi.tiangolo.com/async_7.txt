Title: Understanding Parallel Processing with FastAPI
URL: https://fastapi.tiangolo.com/async/
Summary: The section illustrates the concept of parallel processing using an analogy of ordering burgers at a fast-food restaurant with multiple cashiers/cooks who prepare orders simultaneously. This emphasizes how tasks can be handled concurrently to improve efficiency.
---

## Parallel Burgers[Â¶](https://fastapi.tiangolo.com/async/#parallel-burgers "Permanent link")
Now let's imagine these aren't "Concurrent Burgers", but "Parallel Burgers".
You go with your crush to get parallel fast food.
You stand in line while several (let's say 8) cashiers that at the same time are cooks take the orders from the people in front of you.
Everyone before you is waiting for their burgers to be ready before leaving the counter because each of the 8 cashiers goes and prepares the burger right away before getting the next order.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-01.png)
Then it's finally your turn, you place your order of 2 very fancy burgers for your crush and you.
You pay ğŸ’¸.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-02.png)
The cashier goes to the kitchen.
You wait, standing in front of the counter ğŸ•™, so that no one else takes your burgers before you do, as there are no numbers for turns.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-03.png)
As you and your crush are busy not letting anyone get in front of you and take your burgers whenever they arrive, you cannot pay attention to your crush. ğŸ˜
This is "synchronous" work, you are "synchronized" with the cashier/cook ğŸ‘¨â€ğŸ³. You have to wait ğŸ•™ and be there at the exact moment that the cashier/cook ğŸ‘¨â€ğŸ³ finishes the burgers and gives them to you, or otherwise, someone else might take them.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-04.png)
Then your cashier/cook ğŸ‘¨â€ğŸ³ finally comes back with your burgers, after a long time waiting ğŸ•™ there in front of the counter.
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-05.png)
You take your burgers and go to the table with your crush.
You just eat them, and you are done. â¹
![](https://fastapi.tiangolo.com/img/async/parallel-burgers/parallel-burgers-06.png)
There was not much talk or flirting as most of the time was spent waiting ğŸ•™ in front of the counter. ğŸ˜
Info
Beautiful illustrations by [Ketrina Thompson](https://www.instagram.com/ketrinadrawsalot). ğŸ¨
In this scenario of the parallel burgers, you are a computer / program ğŸ¤– with two processors (you and your crush), both waiting ğŸ•™ and dedicating their attention â¯ to be "waiting on the counter" ğŸ•™ for a long time.
The fast food store has 8 processors (cashiers/cooks). While the concurrent burgers store might have had only 2 (one cashier and one cook).
But still, the final experience is not the best. ğŸ˜
This would be the parallel equivalent story for burgers. ğŸ”
For a more "real life" example of this, imagine a bank.
Up to recently, most of the banks had multiple cashiers ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ and a big line ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™ğŸ•™.
All of the cashiers doing all the work with one client after the other ğŸ‘¨â€ğŸ’¼â¯.
And you have to wait ğŸ•™ in the line for a long time or you lose your turn.
You probably wouldn't want to take your crush ğŸ˜ with you to run errands at the bank ğŸ¦.
### Burger Conclusion[Â¶](https://fastapi.tiangolo.com/async/#burger-conclusion "Permanent link")
In this scenario of "fast food burgers with your crush", as there is a lot of waiting ğŸ•™, it makes a lot more sense to have a concurrent system â¸ğŸ”€â¯.
This is the case for most of the web applications.
Many, many users, but your server is waiting ğŸ•™ for their not-so-good connection to send their requests.
And then waiting ğŸ•™ again for the responses to come back.
This "waiting" ğŸ•™ is measured in microseconds, but still, summing it all, it's a lot of waiting in the end.
That's why it makes a lot of sense to use asynchronous â¸ğŸ”€â¯ code for web APIs.
This kind of asynchronicity is what made NodeJS popular (even though NodeJS is not parallel) and that's the strength of Go as a programming language.
And that's the same level of performance you get with **FastAPI**.
And as you can have parallelism and asynchronicity at the same time, you get higher performance than most of the tested NodeJS frameworks and on par with Go, which is a compiled language closer to C [(all thanks to Starlette)](https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1).
### Is concurrency better than parallelism?[Â¶](https://fastapi.tiangolo.com/async/#is-concurrency-better-than-parallelism "Permanent link")
Nope! That's not the moral of the story.
Concurrency is different than parallelism. And it is better on **specific** scenarios that involve a lot of waiting. Because of that, it generally is a lot better than parallelism for web application development.